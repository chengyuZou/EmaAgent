import json
from typing import List, Dict
import re

class ScriptMerger:
    def __init__(self, window_size=6, overlap=2):
        """
        window_size: æ¯ä¸ªå—åŒ…å«å¤šå°‘å¥å¯¹è¯ (å»ºè®® 5-10 å¥)
        overlap: ç›¸é‚»å—é‡å å¤šå°‘å¥ (ä¿è¯ä¸Šä¸‹æ–‡è¿ç»­æ€§)
        """
        self.window_size = window_size
        self.overlap = overlap
    
    def _extract_trial_info(self, chunk_id: str) -> int:
        """ä» chunk_id æå– Trial åºå·"""
        # ä¾‹å¦‚: "0204Trial06_Hanna006->0204Trial07_Miria002"
        trial_match = re.search(r'Trial(\d+)', chunk_id)

        return int(trial_match.group(1)) if trial_match else 0
    
    def _extract_adv_info(self, chunk_id: str) -> int:
        """ä» chunk_id æå– Adv åºå·"""
        # ä¾‹å¦‚: "0101Adv02_Ema003->0101Adv02_Ema013"
        # æå–èµ·å§‹çš„ Adv ç¼–å·
        adv_match = re.search(r'Adv(\d+)', chunk_id)
        return int(adv_match.group(1)) if adv_match else 0
    
    def _normalize_progress_by_chapter(self, merged_data: List[Dict]) -> List[Dict]:
        """æŒ‰ç« èŠ‚å½’ä¸€åŒ– progress_score"""

        # æŒ‰ç« èŠ‚åˆ†ç»„
        chapter_groups: Dict[str, List[Dict]] = {}
        for item in merged_data:
            chapter_key = item['start_chapter']  # å–èµ·å§‹ç« èŠ‚
            if chapter_key not in chapter_groups:
                chapter_groups[chapter_key] = []
            chapter_groups[chapter_key].append(item)

        # é€ç« èŠ‚å¤„ç†
        for chapter, items in chapter_groups.items():
            # åˆ†ç¦» Trial å’Œ Adv
            trial_items = [item for item in items if item.get('is_trial', False)]
            adv_items = [item for item in items if not item.get('is_trial', False)]

            # å¤„ç† Trial éƒ¨åˆ†
            if trial_items:
                max_trial = max(item['trial_index'] for item in trial_items)
                for item in trial_items:
                    item['progress_score'] = item['trial_index'] / max_trial if max_trial > 0 else 0.0

            # ğŸ’¡ å¤„ç† Adv éƒ¨åˆ†
            if adv_items:
                # æ‰¾å‡ºè¯¥ç« èŠ‚æœ€å¤§çš„ Adv ç¼–å·
                max_adv = max(item['adv_index'] for item in adv_items)
                for item in adv_items:
                    # å½’ä¸€åŒ–åˆ° 0-1 åŒºé—´
                    item['progress_score'] = item['adv_index'] / max_adv if max_adv > 0 else 0.0

        return merged_data


    def merge_dialogues(self, input_file: str, output_file: str):
        with open(input_file, 'r', encoding='utf-8') as f:
            raw_data = json.load(f)

        merged_data = []
        
        # 1. æŒ‰å‘¨ç›®åˆ†ç»„,å…±ä¸‰ä¸ªå‘¨ç›®
        grouped_by_file = {}
        for item in raw_data:
            timeline = item['timeline']
            if timeline not in grouped_by_file:
                grouped_by_file[timeline] = []
            grouped_by_file[timeline].append(item)

        # 2. æ‰§è¡Œæ»‘åŠ¨çª—å£åˆå¹¶
        for timeline, items in grouped_by_file.items():
            total_items = len(items)
            # ä½¿ç”¨æ­¥é•¿ step = window_size - overlap
            step = self.window_size - self.overlap
            
            for i in range(0, total_items, step):
                # è·å–å½“å‰çª—å£çš„åˆ‡ç‰‡
                window_items = items[i : i + self.window_size]
                if not window_items:
                    break
                
                # æ„å»ºåˆå¹¶åçš„æ–‡æœ¬å—
                # æ ¼å¼ï¼š[è§’è‰²]: å°è¯
                context_text = ""
                speakers = set()
                start_id = window_items[0]['id']
                end_id = window_items[-1]['id']

                start_chapter = window_items[0]['chapter']
                end_chapter = window_items[-1]['chapter']

                start_type = window_items[0]['type']
                end_type = window_items[-1]['type']
                is_trial = (start_type == "Trial" or end_type == "Trial")
                
                # æ¯ä¸ªå•å…ƒ JSON
                for item in window_items:
                    # æ‹¼æ¥æ–‡æœ¬ï¼Œä¿ç•™æ¢è¡Œ
                    line = f"{item['speaker']}: {item['text']}\n"
                    context_text += line
                    speakers.add(item['speaker'])


                adv_index = self._extract_adv_info(start_id)
                trial_index = self._extract_trial_info(start_id)

                # 3. æ„é€ æ–°çš„ Chunk å¯¹è±¡
                # è¿™ä¸ª Chunk åŒ…å«äº†ä¸°å¯Œçš„ä¸Šä¸‹æ–‡ï¼Œä¸ä»…çŸ¥é“è¯´äº†ä»€ä¹ˆï¼Œè¿˜çŸ¥é“å‰å› åæœ
                merged_chunk = {
                    "timeline": timeline,
                    "start_chunk_id": start_id,
                    "end_chunk_id": end_id,
                    "start_chapter": start_chapter,
                    "end_chapter": end_chapter,
                    "is_trial": is_trial,
                    "speakers": list(speakers), # å…ƒæ•°æ®ï¼šåŒ…å«å“ªäº›è§’è‰²
                    "content": context_text.strip(), # æ ¸å¿ƒï¼šç”¨äº Embedding çš„é•¿æ–‡æœ¬
                    "adv_index": adv_index,
                    "trial_index": trial_index, # å…ƒæ•°æ®ï¼šTrial åºå·
                    "progress_score": 0.0,
                }
                merged_data.append(merged_chunk)
        
        # æŒ‰ç« èŠ‚å½’ä¸€åŒ–
        merged_data = self._normalize_progress_by_chapter(merged_data)

        # ä¿å­˜ç»“æœ
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(merged_data, f, ensure_ascii=False, indent=2)
        
        print(f"âœ… åˆå¹¶å®Œæˆï¼åŸæ•°æ® {len(raw_data)} æ¡ -> åˆå¹¶å {len(merged_data)} ä¸ªå‰§æƒ…å—ã€‚")

# --- è¿è¡Œé€»è¾‘ ---
if __name__ == "__main__":
    merger = ScriptMerger(window_size=40, overlap=8)
    # è¾“å…¥ä½ ä¹‹å‰ç”Ÿæˆçš„ fixed_dialogues.json
    merger.merge_dialogues("new_output.json", "norm_merged.json")