"""
æ•°æ®æ¸…æ´—è„šæœ¬ï¼šç®€å•æ˜ å°„ç¬¬ä¸‰å‘¨ç›®ç« èŠ‚
ä»…æ›¿æ¢ chapter å’Œ chunk_id å‰ç¼€
"""
import json
import re
from pathlib import Path
from typing import Dict, List


class SimpleThirdLoopMapper:
    """ç¬¬ä¸‰å‘¨ç›®ç®€å•æ˜ å°„å™¨"""
    
    CHAPTER_MAPPING = {
        "Act02_Chapter05": "Act03_Chapter01",
        "Act02_Chapter06": "Act03_Chapter02",
    }
    
    CHUNK_PREFIX_MAPPING = {
        "0205": "0301",
        "0206": "0302",
    }
    
    def __init__(self, input_path: str, output_path: str = None):
        self.input_path = Path(input_path)
        self.output_path = Path(output_path) if output_path else self.input_path.parent / f"{self.input_path.stem}_cleaned.json"
        self.data: List[Dict] = []
    
    def load_data(self):
        """åŠ è½½æ•°æ®"""
        print(f"ðŸ“‚ åŠ è½½æ•°æ®: {self.input_path}")
        with open(self.input_path, 'r', encoding='utf-8') as f:
            self.data = json.load(f)
        print(f"âœ… åŠ è½½å®Œæˆï¼Œå…± {len(self.data)} æ¡è®°å½•")
    
    def map_third_loop(self):
        """æ˜ å°„ç¬¬ä¸‰å‘¨ç›®æ•°æ®"""
        print("\nðŸ”„ æ˜ å°„ç¬¬ä¸‰å‘¨ç›®ç« èŠ‚...")
        
        mapped_count = 0
        for item in self.data:
            # åªå¤„ç†ç¬¬ä¸‰å‘¨ç›®
            if item.get("timeline") != "3rd_Loop":
                continue
            
            # èŽ·å–å½“å‰ç« èŠ‚
            start_chapter = item.get("start_chapter", "")
            end_chapter = item.get("end_chapter", "")
            
            # æ˜ å°„ç« èŠ‚
            if start_chapter in self.CHAPTER_MAPPING:
                item["start_chapter"] = self.CHAPTER_MAPPING[start_chapter]
                
            if end_chapter in self.CHAPTER_MAPPING:
                item["end_chapter"] = self.CHAPTER_MAPPING[end_chapter]
            
            # æ˜ å°„ chunk_id å‰ç¼€
            start_chunk_id = item.get("start_chunk_id", "")
            end_chunk_id = item.get("end_chunk_id", "")
            
            item["start_chunk_id"] = self._replace_chunk_prefix(start_chunk_id)
            item["end_chunk_id"] = self._replace_chunk_prefix(end_chunk_id)
            
            mapped_count += 1
        
        print(f"âœ… æ˜ å°„å®Œæˆï¼Œå…±å¤„ç† {mapped_count} æ¡ç¬¬ä¸‰å‘¨ç›®è®°å½•")
    
    def _replace_chunk_prefix(self, chunk_id: str) -> str:
        """æ›¿æ¢ chunk_id çš„å‰ç¼€ï¼ˆ0205->0301, 0206->0302ï¼‰"""
        if not chunk_id:
            return chunk_id
        
        # æå–å‰4ä½æ•°å­—å‰ç¼€
        match = re.match(r'^(\d{4})(.*)', chunk_id)
        if not match:
            return chunk_id
        
        old_prefix, rest = match.groups()
        
        # æŸ¥æ‰¾æ˜ å°„
        new_prefix = self.CHUNK_PREFIX_MAPPING.get(old_prefix, old_prefix)
        
        return f"{new_prefix}{rest}"
    
    def save(self):
        """ä¿å­˜æ•°æ®"""
        print(f"\nðŸ’¾ ä¿å­˜æ•°æ®åˆ°: {self.output_path}")
        
        with open(self.output_path, 'w', encoding='utf-8') as f:
            json.dump(self.data, f, ensure_ascii=False, indent=2)
        
        print(f"âœ… ä¿å­˜å®Œæˆï¼Œå…± {len(self.data)} æ¡è®°å½•")
    
    def verify(self):
        """éªŒè¯æ˜ å°„ç»“æžœ"""
        print("\nðŸ” éªŒè¯æ˜ å°„ç»“æžœ:")
        
        third_loop_items = [item for item in self.data if item.get("timeline") == "3rd_Loop"]
        
        # ç»Ÿè®¡ç« èŠ‚åˆ†å¸ƒ
        chapter_counts = {}
        for item in third_loop_items:
            chapter = item.get("start_chapter", "Unknown")
            chapter_counts[chapter] = chapter_counts.get(chapter, 0) + 1
        
        print(f"  ç¬¬ä¸‰å‘¨ç›®ç« èŠ‚åˆ†å¸ƒ:")
        for chapter, count in sorted(chapter_counts.items()):
            print(f"    {chapter}: {count} æ¡")
        
        # æ£€æŸ¥æ˜¯å¦è¿˜æœ‰æ—§ç« èŠ‚
        old_chapters = ["Act02_Chapter05", "Act02_Chapter06"]
        has_old = any(
            item.get("start_chapter") in old_chapters or item.get("end_chapter") in old_chapters
            for item in third_loop_items
        )
        
        print(f"  æ˜¯å¦è¿˜æœ‰æ—§ç« èŠ‚ID: {'âŒ æ˜¯' if has_old else 'âœ… å¦'}")
        
        # æ£€æŸ¥ chunk_id å‰ç¼€
        old_prefixes = ["0205", "0206"]
        has_old_prefix = any(
            any(item.get("start_chunk_id", "").startswith(p) or 
                item.get("end_chunk_id", "").startswith(p) for p in old_prefixes)
            for item in third_loop_items
        )
        
        print(f"  æ˜¯å¦è¿˜æœ‰æ—§chunk_idå‰ç¼€: {'âŒ æ˜¯' if has_old_prefix else 'âœ… å¦'}")
    
    def run(self):
        """æ‰§è¡Œå®Œæ•´æµç¨‹"""
        print("="*60)
        print("ðŸ”„ ç¬¬ä¸‰å‘¨ç›®ç®€å•æ˜ å°„è„šæœ¬")
        print("="*60)
        
        self.load_data()
        self.map_third_loop()
        self.save()
        self.verify()
        
        print("\n" + "="*60)
        print("âœ¨ æ˜ å°„å®Œæˆï¼")
        print("="*60)
    
    def print_sample(self, n: int = 3):
        """æ‰“å°æ ·ä¾‹æ•°æ®"""
        third_loop_items = [item for item in self.data if item.get("timeline") == "3rd_Loop"]
        
        print(f"\nðŸ“‹ ç¬¬ä¸‰å‘¨ç›®æ ·ä¾‹æ•°æ®ï¼ˆå‰{n}æ¡ï¼‰:")
        for i, item in enumerate(third_loop_items[:n], 1):
            print(f"\n--- æ ·ä¾‹ {i} ---")
            print(f"Chapter: {item.get('start_chapter')} -> {item.get('end_chapter')}")
            print(f"Chunk ID: {item.get('start_chunk_id')} -> {item.get('end_chunk_id')}")
            print(f"Type: {'Trial' if item.get('is_trial') else 'Adv'}")


def main():
    """ä¸»å‡½æ•°"""
    input_file = r"D:\EmaAgent\EmaAgent-v0.2\Parser\norm_merged.json"
    output_file = r"D:\EmaAgent\EmaAgent-v0.2\Parser\norm_merged_cleaned.json"
    
    mapper = SimpleThirdLoopMapper(input_file, output_file)
    mapper.run()
    mapper.print_sample(n=5)


if __name__ == "__main__":
    main()